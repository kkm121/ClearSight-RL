{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":7350341,"datasetId":4266365,"databundleVersionId":7440786},{"sourceType":"modelInstanceVersion","sourceId":758004,"databundleVersionId":15782186,"modelInstanceId":579016,"modelId":591346}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kkm121121/train-clearsight?scriptVersionId=299311530\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install stable-baselines3[extra] ultralytics gymnasium opencv-python-headless","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T14:45:35.943127Z","iopub.execute_input":"2026-02-22T14:45:35.943468Z","iopub.status.idle":"2026-02-22T14:45:43.437529Z","shell.execute_reply.started":"2026-02-22T14:45:35.943441Z","shell.execute_reply":"2026-02-22T14:45:43.436758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nClearSight-RL: Oracle AI Training Script (GPU Optimized)\n\nThis script trains an AI agent to clean up bad-weather photos (like fog or low light) so that computer vision systems can see objects better. \nIt works by comparing a foggy image to a clear \"answer key\" image. The agent tries out different photo filters (like brightness, contrast, and sharpening). \nIf its edits help a pre-trained YOLO object detector find the exact same objects as the clear image, the agent gets a reward. \nWe are training it for a very long time (150,000 steps) so it learns to be brave and try complex filter combinations instead of giving up early.\n\"\"\"\n\nimport os\nimport cv2\nimport numpy as np\nimport scipy.stats\nimport torch\nimport time\nimport datetime\nimport gymnasium as gym\nfrom gymnasium import spaces\nfrom ultralytics import YOLO\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.callbacks import EvalCallback, BaseCallback, CallbackList\nfrom stable_baselines3.common.vec_env import SubprocVecEnv\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nclass ETACallback(BaseCallback):\n    \"\"\"\n    Custom Kaggle-safe callback to print live ETA and Progress.\n    \"\"\"\n    def __init__(self, total_timesteps, print_freq=2048, verbose=0):\n        super().__init__(verbose)\n        self.total_timesteps = total_timesteps\n        self.print_freq = print_freq\n        self.start_time = None\n\n    def _on_training_start(self) -> None:\n        self.start_time = time.time()\n\n    def _on_step(self) -> bool:\n        if self.num_timesteps % self.print_freq == 0:\n            elapsed_time = time.time() - self.start_time\n            fps = self.num_timesteps / elapsed_time\n            remaining_steps = self.total_timesteps - self.num_timesteps\n            eta_seconds = remaining_steps / fps\n            \n            elapsed_str = str(datetime.timedelta(seconds=int(elapsed_time)))\n            eta_str = str(datetime.timedelta(seconds=int(eta_seconds)))\n            \n            percentage = (self.num_timesteps / self.total_timesteps) * 100\n            print(f\"[{percentage:.1f}%] Steps: {self.num_timesteps}/{self.total_timesteps} | \"\n                  f\"Speed: {int(fps)} it/s | Elapsed: {elapsed_str} | ETA: {eta_str}\")\n        return True\n\ndef calculate_iou(box1, box2):\n    x1 = max(box1[0], box2[0])\n    y1 = max(box1[1], box2[1])\n    x2 = min(box1[2], box2[2])\n    y2 = min(box1[3], box2[3])\n    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n    union = area1 + area2 - intersection\n    return intersection / union if union > 0 else 0\n\nclass ClearSightOracleEnv(gym.Env):\n    def __init__(self, clear_dir=None, hazy_dir=None, max_steps=5):\n        super().__init__()\n        self.clear_dir = clear_dir\n        self.hazy_dir = hazy_dir\n        self.image_pairs = []\n        \n        if self.clear_dir and self.hazy_dir and os.path.exists(self.clear_dir) and os.path.exists(self.hazy_dir):\n            clear_files = [f for f in os.listdir(self.clear_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            clear_map = {os.path.splitext(f)[0]: f for f in clear_files}\n            hazy_files = [f for f in os.listdir(self.hazy_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            \n            for hazy_f in hazy_files:\n                base_name = os.path.splitext(hazy_f)[0]\n                if base_name in clear_map:\n                    self.image_pairs.append({\n                        'clear': os.path.join(self.clear_dir, clear_map[base_name]), \n                        'hazy': os.path.join(self.hazy_dir, hazy_f)\n                    })\n                elif base_name.split('_')[0] in clear_map:\n                    self.image_pairs.append({\n                        'clear': os.path.join(self.clear_dir, clear_map[base_name.split('_')[0]]), \n                        'hazy': os.path.join(self.hazy_dir, hazy_f)\n                    })\n\n        if len(self.image_pairs) == 0:\n            print(\"Warning: No paired images found. Generating synthetic dataset.\")\n            self._generate_synthetic_fallback()\n            \n        print(f\"Loaded {len(self.image_pairs)} paired images.\")\n        self.yolo = None\n        \n        self.max_steps = max_steps\n        self.action_space = spaces.Discrete(6)\n        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)\n        self.current_image = None\n        self.oracle_boxes = []\n        self.current_step = 0\n        self.base_oracle_score = 0.0\n        self.current_oracle_score = 0.0\n\n    def _generate_synthetic_fallback(self):\n        os.makedirs('/tmp/clearsight_dummy/clear', exist_ok=True)\n        os.makedirs('/tmp/clearsight_dummy/hazy', exist_ok=True)\n        img = np.ones((480, 640, 3), dtype=np.uint8) * 200\n        cv2.circle(img, (320, 240), 50, (0, 0, 255), -1) \n        clear_path = '/tmp/clearsight_dummy/clear/fallback_001.jpg'\n        cv2.imwrite(clear_path, img)\n        hazy_img = cv2.addWeighted(img, 0.4, np.ones_like(img)*255, 0.6, 0)\n        hazy_path = '/tmp/clearsight_dummy/hazy/fallback_001.jpg'\n        cv2.imwrite(hazy_path, hazy_img)\n        self.image_pairs.append({'clear': clear_path, 'hazy': hazy_path})\n\n    def _extract_features(self, img):\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        mean_brightness = np.mean(gray)\n        contrast = np.std(gray)\n        hist = np.histogram(gray, bins=256, range=(0, 256))[0]\n        hist = hist / (hist.sum() + 1e-5)\n        entropy = scipy.stats.entropy(hist + 1e-5)\n        blur = cv2.Laplacian(gray, cv2.CV_64F).var()\n        return np.array([mean_brightness, contrast, entropy, blur], dtype=np.float32)\n\n    def _calculate_oracle_reward(self, img):\n        if getattr(self, 'yolo', None) is None:\n            self.yolo = YOLO('yolov8n.pt')\n            self.yolo.to(device)\n            \n        results = self.yolo(img, verbose=False, device=device)[0]\n        curr_boxes = [b for b in results.boxes if b.conf[0].item() > 0.25]\n        reward = 0.0\n        matched_oracle_idx = set()\n        \n        for c_box in curr_boxes:\n            c_conf = c_box.conf[0].item()\n            c_cls = int(c_box.cls[0].item())\n            c_xyxy = c_box.xyxy[0].cpu().numpy()\n            best_iou = 0\n            best_idx = -1\n            \n            for i, o_box in enumerate(self.oracle_boxes):\n                if i in matched_oracle_idx: continue\n                if int(o_box.cls[0].item()) != c_cls: continue\n                o_xyxy = o_box.xyxy[0].cpu().numpy()\n                iou = calculate_iou(c_xyxy, o_xyxy)\n                if iou > best_iou:\n                    best_iou = iou\n                    best_idx = i\n                    \n            if best_iou > 0.4:\n                reward += c_conf\n                matched_oracle_idx.add(best_idx)\n            else:\n                reward -= (c_conf * 1.5) \n        return reward\n\n    def _apply_action(self, img, action):\n        if action == 1: return cv2.convertScaleAbs(img, alpha=1.1, beta=15)\n        elif action == 2: return cv2.convertScaleAbs(img, alpha=0.9, beta=-15)\n        elif action == 3:\n            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n            l, a, b = cv2.split(lab)\n            cl = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(l)\n            return cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)\n        elif action == 4:\n            kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n            return cv2.filter2D(img, -1, kernel)\n        elif action == 5:\n            return cv2.bilateralFilter(img, 9, 75, 75)\n        return img\n\n    def reset(self, seed=None, options=None):\n        super().reset(seed=seed)\n        self.current_step = 0\n        \n        if getattr(self, 'yolo', None) is None:\n            self.yolo = YOLO('yolov8n.pt')\n            self.yolo.to(device)\n            \n        if self.image_pairs:\n            idx = self.np_random.integers(0, len(self.image_pairs))\n            clear_img = cv2.imread(self.image_pairs[idx]['clear'])\n            self.current_image = cv2.imread(self.image_pairs[idx]['hazy'])\n            oracle_results = self.yolo(clear_img, verbose=False, device=device)[0]\n            self.oracle_boxes = [b for b in oracle_results.boxes if b.conf[0].item() > 0.3]\n        else:\n            self.current_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n            self.oracle_boxes = []\n            \n        self.base_oracle_score = self._calculate_oracle_reward(self.current_image)\n        self.current_oracle_score = self.base_oracle_score\n        return self._extract_features(self.current_image), {}\n\n    def step(self, action):\n        self.current_step += 1\n        terminated = False\n        truncated = False\n        reward = 0.0\n        \n        if action == 0:\n            terminated = True\n            if self.current_oracle_score > self.base_oracle_score * 1.2:\n                reward += 3.0 \n        else:\n            self.current_image = self._apply_action(self.current_image, action)\n            new_oracle_score = self._calculate_oracle_reward(self.current_image)\n            delta_score = new_oracle_score - self.current_oracle_score\n            reward += delta_score\n            self.current_oracle_score = new_oracle_score\n            reward -= 0.1 \n\n        if self.current_step >= self.max_steps:\n            truncated = True\n            \n        info = {\"step\": self.current_step, \"oracle_score\": self.current_oracle_score}\n        return self._extract_features(self.current_image), reward, terminated, truncated, info\n\nif __name__ == \"__main__\":\n    CLEAR_DIR = '/kaggle/input/datasets/brunobelloni/outdoor-training-set-ots-reside/clear'\n    HAZY_DIR = '/kaggle/input/datasets/brunobelloni/outdoor-training-set-ots-reside/hazy'\n    \n    print(f\"Hardware detected: {device.upper()}\")\n    print(\"Initializing multi-processing environment...\")\n    \n    def make_env():\n        return ClearSightOracleEnv(clear_dir=CLEAR_DIR, hazy_dir=HAZY_DIR, max_steps=5)\n    \n    vec_env = make_vec_env(make_env, n_envs=8, vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"spawn\"})\n    eval_env = make_vec_env(make_env, n_envs=1, vec_env_cls=SubprocVecEnv, vec_env_kwargs={\"start_method\": \"spawn\"})\n    eval_callback = EvalCallback(eval_env, best_model_save_path='./logs/', log_path='./logs/', eval_freq=2000, deterministic=True, render=False)\n    \n    total_steps = 150000\n    eta_callback = ETACallback(total_timesteps=total_steps, print_freq=2048)\n    callback_list = CallbackList([eta_callback, eval_callback])\n    \n    print(\"Configuring PPO Agent...\")\n    model = PPO(\"MlpPolicy\", vec_env, verbose=1, learning_rate=3e-4, n_steps=1024, batch_size=256, n_epochs=10, gamma=0.99, device=device)\n    \n    print(\"Starting Training Phase...\")\n    print(\"NOTE: The AI is collecting its first batch of images. The custom ETA tracker will print updates shortly...\")\n    start_time = time.time()\n    model.learn(total_timesteps=total_steps, callback=callback_list)\n    \n    end_time = time.time()\n    elapsed_time = end_time - start_time\n    formatted_time = str(datetime.timedelta(seconds=int(elapsed_time)))\n    \n    print(f\"Training Complete in {formatted_time}. Saving model...\")\n    model.save(\"clearsight_agent_ots_oracle\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T04:50:44.490609Z","iopub.execute_input":"2026-02-22T04:50:44.490954Z","iopub.status.idle":"2026-02-22T05:32:09.100401Z","shell.execute_reply.started":"2026-02-22T04:50:44.490911Z","shell.execute_reply":"2026-02-22T05:32:09.100142Z"}},"outputs":[],"execution_count":null}]}